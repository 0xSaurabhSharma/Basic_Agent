{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper,ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_api_wrap = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=250)\n",
    "wiki = WikipediaQueryRun(api_wrapper=wiki_api_wrap)\n",
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_api_wrap = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=250)\n",
    "arxiv = ArxivQueryRun(api_wrapper=arxiv_api_wrap)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki, arxiv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Custom tools[RAG Tool]\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/agent-env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "os.environ['HF_TOKEN']= os.getenv('HF_TOKEN')\n",
    "embeddings = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x73cc721ff6b0>, search_kwargs={})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader=WebBaseLoader(\"https://paulgraham.com/best.html\")\n",
    "docs=loader.load()\n",
    "documents=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)\n",
    "vectordb=FAISS.from_documents(documents,embeddings)\n",
    "retriever=vectordb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Essay Search'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting retriever into agentic tool\n",
    "\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(retriever, 'Essay Search','Ask me about this essay...')\n",
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki, arxiv, retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrating tools with llms\n",
    "from langchain_groq import ChatGroq\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "llm = ChatGroq(groq_api_key=groq_api_key, model_name='Llama3-8b-8192')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x73ccc4568c20>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x73ccc4568c20>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x73cc6b09a5d0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x73cc6b062900>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'Essay Search', 'description': 'Ask me about this essay...', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_openai_tools_agent\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x73ccc4568c20>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x73ccc4568c20>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x73cc6b09a5d0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x73cc6b062900>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'Essay Search', 'description': 'Ask me about this essay...', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/opt/conda/envs/agent-env/lib/python3.12/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=250)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250)), Tool(name='Essay Search', description='Ask me about this essay...', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x73ccabc0de40>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x73cc721ff6b0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x73ccab97f380>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x73cc721ff6b0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agent Executer\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_exectuor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_exectuor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'What is this article about?'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Whataboutism\n",
      "Summary: Whataboutism or whataboutery (as in \"what about ...?\") is a pejorative for the strategy of responding to an accusation with a counter-accusation instead of a defense against the original accusation. \n",
      "From a logical and arg\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Essay Search` with `{'query': 'What is this article about?'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mThe Best Essay\n",
      "\n",
      "after decades of training, this is hard for new arrivals in the real\n",
      "world to grasp. Helping them overcome such institutional lies will\n",
      "work as long as the institutions remain broken. \n",
      "[12]Another recipe for timelessness is to write about things readers\n",
      "already know, but in much more detail than can be transmitted\n",
      "culturally. \"Everyone knows,\" for example, that it can be rewarding\n",
      "to have kids. But till you have them you don't know precisely what\n",
      "forms that takes, and even then much of what you know you may never\n",
      "have put into words.I've written about all these kinds of topics. But I didn't do it\n",
      "in a deliberate attempt to write essays that were timeless in the\n",
      "stricter sense. And indeed, the fact that this depends on one's ideas\n",
      "not sticking suggests that it's not worth making a deliberate attempt\n",
      "to. You should write about topics of timeless importance, yes, but\n",
      "if you do such a good job that your conclusions stick and future\n",
      "\n",
      "March 2024Despite its title this isn't meant to be the best essay. My goal\n",
      "here is to figure out what the best essay would be like.It would be well-written, but you can write well about any topic.\n",
      "What made it special would be what it was about.Obviously some topics would be better than others. It probably\n",
      "wouldn't be about this year's lipstick colors. But it wouldn't be\n",
      "vaporous talk about elevated themes either. A good essay has to be\n",
      "surprising. It has to tell people something they don't already know.The best essay would be on the most important topic you could tell\n",
      "people something surprising about.That may sound obvious, but it has some unexpected consequences.\n",
      "One is that science enters the picture like an elephant stepping\n",
      "into a rowboat. For example, Darwin first described the idea of\n",
      "natural selection in an essay written in 1844.\n",
      "Talk about an\n",
      "important topic you could tell people something surprising about.\n",
      "If that's the test of a great essay, this was surely the best one\n",
      "\n",
      "if you want to disqualify essays on this account. How do you decide\n",
      "where the cutoff should be? If a virus kills off everyone except a \n",
      "handful of people sequestered at Los Alamos,\n",
      "could an essay that had been disqualified now be eligible? Etc.Darwin's 1844 essay was derived from an earlier version written in 1839.\n",
      "Extracts from it were published in 1858.[2]\n",
      "When you find yourself very curious about an apparently minor\n",
      "question, that's an exciting sign. Evolution has designed you to\n",
      "pay attention to things that matter. So when you're very curious\n",
      "about something random, that could mean you've unconsciously noticed\n",
      "it's less random than it seems.[3]\n",
      "Corollary: If you're not intellectually honest, your writing\n",
      "won't just be biased, but also boring, because you'll miss all the\n",
      "ideas you'd have discovered if you pushed for the truth.[4]\n",
      "Sometimes this process begins before you start writing.\n",
      "Sometimes you've already figured out the first few things you want\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'what is the best essay'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Essay\n",
      "Summary: An essay is, generally, a piece of writing that gives the author's own argument, but the definition is vague, overlapping with those of a letter, a paper, an article, a pamphlet, and a short story. Essays have been sub-classified\u001b[0m\u001b[32;1m\u001b[1;3mI think I have the answer!\n",
      "\n",
      "The article is about the concept of an essay and its characteristics. It explores what makes a good essay, including the importance of surprising readers with new information, being well-written, and being intellectually honest. The article also touches on the idea that essays can be timeless and that some topics are more suitable for essays than others.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is this article about ??',\n",
       " 'output': 'I think I have the answer!\\n\\nThe article is about the concept of an essay and its characteristics. It explores what makes a good essay, including the importance of surprising readers with new information, being well-written, and being intellectually honest. The article also touches on the idea that essays can be timeless and that some topics are more suitable for essays than others.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_exectuor.invoke({'input':'What is this article about ??'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Essay Search` with `{'query': 'timeless essays self transformation'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mend to end by returning to a question you skipped earlier. Usually\n",
      "it requires some sleight of hand to make the essay flow continuously\n",
      "at this point, but not this time. This time I actually need an\n",
      "example of the phenomenon. For example, we discovered earlier that\n",
      "the best possible essay wouldn't usually be timeless in the way the\n",
      "best painting would. This seems surprising enough to be\n",
      "worth investigating further.There are two senses in which an essay can be timeless: to be about\n",
      "a matter of permanent importance, and always to have the same effect\n",
      "on readers. With art these two senses blend together. Art that\n",
      "looked beautiful to the ancient Greeks still looks beautiful to us.\n",
      "But with essays the two senses diverge, because essays\n",
      "teach, and you can't teach people something they already know.\n",
      "Natural selection is certainly a matter of permanent importance,\n",
      "but an essay explaining it couldn't have the same effect on us that\n",
      "\n",
      "The Best Essay\n",
      "\n",
      "after decades of training, this is hard for new arrivals in the real\n",
      "world to grasp. Helping them overcome such institutional lies will\n",
      "work as long as the institutions remain broken. \n",
      "[12]Another recipe for timelessness is to write about things readers\n",
      "already know, but in much more detail than can be transmitted\n",
      "culturally. \"Everyone knows,\" for example, that it can be rewarding\n",
      "to have kids. But till you have them you don't know precisely what\n",
      "forms that takes, and even then much of what you know you may never\n",
      "have put into words.I've written about all these kinds of topics. But I didn't do it\n",
      "in a deliberate attempt to write essays that were timeless in the\n",
      "stricter sense. And indeed, the fact that this depends on one's ideas\n",
      "not sticking suggests that it's not worth making a deliberate attempt\n",
      "to. You should write about topics of timeless importance, yes, but\n",
      "if you do such a good job that your conclusions stick and future\n",
      "\n",
      "teach, and you can't teach people something they already know.\n",
      "Natural selection is certainly a matter of permanent importance,\n",
      "but an essay explaining it couldn't have the same effect on us that\n",
      "it would have had on Darwin's contemporaries, precisely because his\n",
      "ideas were so successful that everyone already knows about them.\n",
      "[10]I imagined when I started writing this that the best possible essay\n",
      "would be timeless in the stricter, evergreen sense: that it would\n",
      "contain some deep, timeless wisdom that would appeal equally to\n",
      "Aristotle and Feynman. That doesn't seem to be true. But if the\n",
      "best possible essay wouldn't usually be timeless in this stricter\n",
      "sense, what would it take to write essays that were?The answer to that turns out to be very strange: to be the evergreen\n",
      "kind of timeless, an essay has to be ineffective, in the sense that\n",
      "its discoveries aren't assimilated into our shared culture. Otherwise\n",
      "there will be nothing new in it for the second generation of readers.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Essay Search` with `{'query': 'timeless essays life partner'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mafter decades of training, this is hard for new arrivals in the real\n",
      "world to grasp. Helping them overcome such institutional lies will\n",
      "work as long as the institutions remain broken. \n",
      "[12]Another recipe for timelessness is to write about things readers\n",
      "already know, but in much more detail than can be transmitted\n",
      "culturally. \"Everyone knows,\" for example, that it can be rewarding\n",
      "to have kids. But till you have them you don't know precisely what\n",
      "forms that takes, and even then much of what you know you may never\n",
      "have put into words.I've written about all these kinds of topics. But I didn't do it\n",
      "in a deliberate attempt to write essays that were timeless in the\n",
      "stricter sense. And indeed, the fact that this depends on one's ideas\n",
      "not sticking suggests that it's not worth making a deliberate attempt\n",
      "to. You should write about topics of timeless importance, yes, but\n",
      "if you do such a good job that your conclusions stick and future\n",
      "\n",
      "teach, and you can't teach people something they already know.\n",
      "Natural selection is certainly a matter of permanent importance,\n",
      "but an essay explaining it couldn't have the same effect on us that\n",
      "it would have had on Darwin's contemporaries, precisely because his\n",
      "ideas were so successful that everyone already knows about them.\n",
      "[10]I imagined when I started writing this that the best possible essay\n",
      "would be timeless in the stricter, evergreen sense: that it would\n",
      "contain some deep, timeless wisdom that would appeal equally to\n",
      "Aristotle and Feynman. That doesn't seem to be true. But if the\n",
      "best possible essay wouldn't usually be timeless in this stricter\n",
      "sense, what would it take to write essays that were?The answer to that turns out to be very strange: to be the evergreen\n",
      "kind of timeless, an essay has to be ineffective, in the sense that\n",
      "its discoveries aren't assimilated into our shared culture. Otherwise\n",
      "there will be nothing new in it for the second generation of readers.\n",
      "\n",
      "The Best Essay\n",
      "\n",
      "end to end by returning to a question you skipped earlier. Usually\n",
      "it requires some sleight of hand to make the essay flow continuously\n",
      "at this point, but not this time. This time I actually need an\n",
      "example of the phenomenon. For example, we discovered earlier that\n",
      "the best possible essay wouldn't usually be timeless in the way the\n",
      "best painting would. This seems surprising enough to be\n",
      "worth investigating further.There are two senses in which an essay can be timeless: to be about\n",
      "a matter of permanent importance, and always to have the same effect\n",
      "on readers. With art these two senses blend together. Art that\n",
      "looked beautiful to the ancient Greeks still looks beautiful to us.\n",
      "But with essays the two senses diverge, because essays\n",
      "teach, and you can't teach people something they already know.\n",
      "Natural selection is certainly a matter of permanent importance,\n",
      "but an essay explaining it couldn't have the same effect on us that\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Essay Search` with `{'query': 'timeless essays relationship'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mend to end by returning to a question you skipped earlier. Usually\n",
      "it requires some sleight of hand to make the essay flow continuously\n",
      "at this point, but not this time. This time I actually need an\n",
      "example of the phenomenon. For example, we discovered earlier that\n",
      "the best possible essay wouldn't usually be timeless in the way the\n",
      "best painting would. This seems surprising enough to be\n",
      "worth investigating further.There are two senses in which an essay can be timeless: to be about\n",
      "a matter of permanent importance, and always to have the same effect\n",
      "on readers. With art these two senses blend together. Art that\n",
      "looked beautiful to the ancient Greeks still looks beautiful to us.\n",
      "But with essays the two senses diverge, because essays\n",
      "teach, and you can't teach people something they already know.\n",
      "Natural selection is certainly a matter of permanent importance,\n",
      "but an essay explaining it couldn't have the same effect on us that\n",
      "\n",
      "after decades of training, this is hard for new arrivals in the real\n",
      "world to grasp. Helping them overcome such institutional lies will\n",
      "work as long as the institutions remain broken. \n",
      "[12]Another recipe for timelessness is to write about things readers\n",
      "already know, but in much more detail than can be transmitted\n",
      "culturally. \"Everyone knows,\" for example, that it can be rewarding\n",
      "to have kids. But till you have them you don't know precisely what\n",
      "forms that takes, and even then much of what you know you may never\n",
      "have put into words.I've written about all these kinds of topics. But I didn't do it\n",
      "in a deliberate attempt to write essays that were timeless in the\n",
      "stricter sense. And indeed, the fact that this depends on one's ideas\n",
      "not sticking suggests that it's not worth making a deliberate attempt\n",
      "to. You should write about topics of timeless importance, yes, but\n",
      "if you do such a good job that your conclusions stick and future\n",
      "\n",
      "to. You should write about topics of timeless importance, yes, but\n",
      "if you do such a good job that your conclusions stick and future\n",
      "generations find your essay obvious instead of novel, so much the\n",
      "better. You've crossed into Darwin territory.Writing about topics of timeless importance is an instance of\n",
      "something even more general, though: breadth of applicability. And\n",
      "there are more kinds of breadth than chronological — applying to\n",
      "lots of different fields, for example. So breadth is the ultimate\n",
      "aim.I already aim for it. Breadth and novelty are the two things I'm\n",
      "always chasing. But I'm glad I understand where timelessness fits.I understand better where a lot of things fit now. This essay has\n",
      "been a kind of tour of essay writing. I started out hoping to get\n",
      "advice about topics; if you assume good writing, the only thing\n",
      "left to differentiate the best essay is its topic. And I did get\n",
      "advice about topics: discover natural selection. Yeah, that would\n",
      "\n",
      "teach, and you can't teach people something they already know.\n",
      "Natural selection is certainly a matter of permanent importance,\n",
      "but an essay explaining it couldn't have the same effect on us that\n",
      "it would have had on Darwin's contemporaries, precisely because his\n",
      "ideas were so successful that everyone already knows about them.\n",
      "[10]I imagined when I started writing this that the best possible essay\n",
      "would be timeless in the stricter, evergreen sense: that it would\n",
      "contain some deep, timeless wisdom that would appeal equally to\n",
      "Aristotle and Feynman. That doesn't seem to be true. But if the\n",
      "best possible essay wouldn't usually be timeless in this stricter\n",
      "sense, what would it take to write essays that were?The answer to that turns out to be very strange: to be the evergreen\n",
      "kind of timeless, an essay has to be ineffective, in the sense that\n",
      "its discoveries aren't assimilated into our shared culture. Otherwise\n",
      "there will be nothing new in it for the second generation of readers.\u001b[0m\u001b[32;1m\u001b[1;3mThe essays on self-transformation, life partner, and relationships are not explicitly mentioned in this output. However, there are some points that could be indirectly related to these topics:\n",
      "\n",
      "* The idea of \"breadth of applicability\" could be applied to self-transformation, as it involves finding ways to apply new knowledge and skills to one's life.\n",
      "* The concept of \"novelty\" could be relevant to finding a life partner, as it involves discovering new and unique individuals who can bring new experiences and perspectives to one's life.\n",
      "* The discussion of \"timelessness\" could be applied to relationships, as it involves finding ways to make a relationship last and remain meaningful over time.\n",
      "\n",
      "However, these connections are not explicit and would require further interpretation and analysis to be applied to the topics of self-transformation, life partner, and relationships.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What are some timeless essays ?? give me some focused on self transformation, life partner & relationship',\n",
       " 'output': 'The essays on self-transformation, life partner, and relationships are not explicitly mentioned in this output. However, there are some points that could be indirectly related to these topics:\\n\\n* The idea of \"breadth of applicability\" could be applied to self-transformation, as it involves finding ways to apply new knowledge and skills to one\\'s life.\\n* The concept of \"novelty\" could be relevant to finding a life partner, as it involves discovering new and unique individuals who can bring new experiences and perspectives to one\\'s life.\\n* The discussion of \"timelessness\" could be applied to relationships, as it involves finding ways to make a relationship last and remain meaningful over time.\\n\\nHowever, these connections are not explicit and would require further interpretation and analysis to be applied to the topics of self-transformation, life partner, and relationships.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_exectuor.invoke({'input':'What are some timeless essays ?? give me some focused on self transformation, life partner & relationship'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Essay Search` with `{'query': 'greatest essays 2024'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mThe Best Essay\n",
      "\n",
      "March 2024Despite its title this isn't meant to be the best essay. My goal\n",
      "here is to figure out what the best essay would be like.It would be well-written, but you can write well about any topic.\n",
      "What made it special would be what it was about.Obviously some topics would be better than others. It probably\n",
      "wouldn't be about this year's lipstick colors. But it wouldn't be\n",
      "vaporous talk about elevated themes either. A good essay has to be\n",
      "surprising. It has to tell people something they don't already know.The best essay would be on the most important topic you could tell\n",
      "people something surprising about.That may sound obvious, but it has some unexpected consequences.\n",
      "One is that science enters the picture like an elephant stepping\n",
      "into a rowboat. For example, Darwin first described the idea of\n",
      "natural selection in an essay written in 1844.\n",
      "Talk about an\n",
      "important topic you could tell people something surprising about.\n",
      "If that's the test of a great essay, this was surely the best one\n",
      "\n",
      "natural selection in an essay written in 1844.\n",
      "Talk about an\n",
      "important topic you could tell people something surprising about.\n",
      "If that's the test of a great essay, this was surely the best one\n",
      "written in 1844. \n",
      "And indeed, the best possible essay at any given\n",
      "time would usually be one describing the most important scientific\n",
      "or technological discovery it was possible to make.\n",
      "[1]Another unexpected consequence: I imagined when I started writing\n",
      "this that the best essay would be fairly timeless — that the best\n",
      "essay you could write in 1844 would be much the same as the best\n",
      "one you could write now. But in fact the opposite seems to be true.\n",
      "It might be true that the best painting would be timeless in this\n",
      "sense. But it wouldn't be impressive to write an essay introducing\n",
      "natural selection now. The best essay now would be one describing\n",
      "a great discovery we didn't yet know about.If the question of how to write the best possible essay reduces to\n",
      "\n",
      "after decades of training, this is hard for new arrivals in the real\n",
      "world to grasp. Helping them overcome such institutional lies will\n",
      "work as long as the institutions remain broken. \n",
      "[12]Another recipe for timelessness is to write about things readers\n",
      "already know, but in much more detail than can be transmitted\n",
      "culturally. \"Everyone knows,\" for example, that it can be rewarding\n",
      "to have kids. But till you have them you don't know precisely what\n",
      "forms that takes, and even then much of what you know you may never\n",
      "have put into words.I've written about all these kinds of topics. But I didn't do it\n",
      "in a deliberate attempt to write essays that were timeless in the\n",
      "stricter sense. And indeed, the fact that this depends on one's ideas\n",
      "not sticking suggests that it's not worth making a deliberate attempt\n",
      "to. You should write about topics of timeless importance, yes, but\n",
      "if you do such a good job that your conclusions stick and future\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Essay Search` with `{'query': 'greatest essays 2024'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mThe Best Essay\n",
      "\n",
      "March 2024Despite its title this isn't meant to be the best essay. My goal\n",
      "here is to figure out what the best essay would be like.It would be well-written, but you can write well about any topic.\n",
      "What made it special would be what it was about.Obviously some topics would be better than others. It probably\n",
      "wouldn't be about this year's lipstick colors. But it wouldn't be\n",
      "vaporous talk about elevated themes either. A good essay has to be\n",
      "surprising. It has to tell people something they don't already know.The best essay would be on the most important topic you could tell\n",
      "people something surprising about.That may sound obvious, but it has some unexpected consequences.\n",
      "One is that science enters the picture like an elephant stepping\n",
      "into a rowboat. For example, Darwin first described the idea of\n",
      "natural selection in an essay written in 1844.\n",
      "Talk about an\n",
      "important topic you could tell people something surprising about.\n",
      "If that's the test of a great essay, this was surely the best one\n",
      "\n",
      "natural selection in an essay written in 1844.\n",
      "Talk about an\n",
      "important topic you could tell people something surprising about.\n",
      "If that's the test of a great essay, this was surely the best one\n",
      "written in 1844. \n",
      "And indeed, the best possible essay at any given\n",
      "time would usually be one describing the most important scientific\n",
      "or technological discovery it was possible to make.\n",
      "[1]Another unexpected consequence: I imagined when I started writing\n",
      "this that the best essay would be fairly timeless — that the best\n",
      "essay you could write in 1844 would be much the same as the best\n",
      "one you could write now. But in fact the opposite seems to be true.\n",
      "It might be true that the best painting would be timeless in this\n",
      "sense. But it wouldn't be impressive to write an essay introducing\n",
      "natural selection now. The best essay now would be one describing\n",
      "a great discovery we didn't yet know about.If the question of how to write the best possible essay reduces to\n",
      "\n",
      "after decades of training, this is hard for new arrivals in the real\n",
      "world to grasp. Helping them overcome such institutional lies will\n",
      "work as long as the institutions remain broken. \n",
      "[12]Another recipe for timelessness is to write about things readers\n",
      "already know, but in much more detail than can be transmitted\n",
      "culturally. \"Everyone knows,\" for example, that it can be rewarding\n",
      "to have kids. But till you have them you don't know precisely what\n",
      "forms that takes, and even then much of what you know you may never\n",
      "have put into words.I've written about all these kinds of topics. But I didn't do it\n",
      "in a deliberate attempt to write essays that were timeless in the\n",
      "stricter sense. And indeed, the fact that this depends on one's ideas\n",
      "not sticking suggests that it's not worth making a deliberate attempt\n",
      "to. You should write about topics of timeless importance, yes, but\n",
      "if you do such a good job that your conclusions stick and future\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Essay Search` with `{'query': 'greatest essays 2024'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mThe Best Essay\n",
      "\n",
      "March 2024Despite its title this isn't meant to be the best essay. My goal\n",
      "here is to figure out what the best essay would be like.It would be well-written, but you can write well about any topic.\n",
      "What made it special would be what it was about.Obviously some topics would be better than others. It probably\n",
      "wouldn't be about this year's lipstick colors. But it wouldn't be\n",
      "vaporous talk about elevated themes either. A good essay has to be\n",
      "surprising. It has to tell people something they don't already know.The best essay would be on the most important topic you could tell\n",
      "people something surprising about.That may sound obvious, but it has some unexpected consequences.\n",
      "One is that science enters the picture like an elephant stepping\n",
      "into a rowboat. For example, Darwin first described the idea of\n",
      "natural selection in an essay written in 1844.\n",
      "Talk about an\n",
      "important topic you could tell people something surprising about.\n",
      "If that's the test of a great essay, this was surely the best one\n",
      "\n",
      "natural selection in an essay written in 1844.\n",
      "Talk about an\n",
      "important topic you could tell people something surprising about.\n",
      "If that's the test of a great essay, this was surely the best one\n",
      "written in 1844. \n",
      "And indeed, the best possible essay at any given\n",
      "time would usually be one describing the most important scientific\n",
      "or technological discovery it was possible to make.\n",
      "[1]Another unexpected consequence: I imagined when I started writing\n",
      "this that the best essay would be fairly timeless — that the best\n",
      "essay you could write in 1844 would be much the same as the best\n",
      "one you could write now. But in fact the opposite seems to be true.\n",
      "It might be true that the best painting would be timeless in this\n",
      "sense. But it wouldn't be impressive to write an essay introducing\n",
      "natural selection now. The best essay now would be one describing\n",
      "a great discovery we didn't yet know about.If the question of how to write the best possible essay reduces to\n",
      "\n",
      "after decades of training, this is hard for new arrivals in the real\n",
      "world to grasp. Helping them overcome such institutional lies will\n",
      "work as long as the institutions remain broken. \n",
      "[12]Another recipe for timelessness is to write about things readers\n",
      "already know, but in much more detail than can be transmitted\n",
      "culturally. \"Everyone knows,\" for example, that it can be rewarding\n",
      "to have kids. But till you have them you don't know precisely what\n",
      "forms that takes, and even then much of what you know you may never\n",
      "have put into words.I've written about all these kinds of topics. But I didn't do it\n",
      "in a deliberate attempt to write essays that were timeless in the\n",
      "stricter sense. And indeed, the fact that this depends on one's ideas\n",
      "not sticking suggests that it's not worth making a deliberate attempt\n",
      "to. You should write about topics of timeless importance, yes, but\n",
      "if you do such a good job that your conclusions stick and future\u001b[0m\u001b[32;1m\u001b[1;3mI apologize, but it seems like the tool call id \"call_vghd\" yielded the same result as the previous tool call id \"call_n0v7\". It appears that the tool is stuck in a loop and is not providing any new or relevant information.\n",
      "\n",
      "As a helpful assistant, I can try to provide a different response or explore other options to answer your question. However, I would like to clarify that the output from the tool seems to be a philosophical essay rather than a list of the greatest essays of 2024.\n",
      "\n",
      "If you would like, I can try to provide a different response or explore other options to answer your question. Please let me know how I can assist you further.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Give me 10 greatest essays of 2024 ??',\n",
       " 'output': 'I apologize, but it seems like the tool call id \"call_vghd\" yielded the same result as the previous tool call id \"call_n0v7\". It appears that the tool is stuck in a loop and is not providing any new or relevant information.\\n\\nAs a helpful assistant, I can try to provide a different response or explore other options to answer your question. However, I would like to clarify that the output from the tool seems to be a philosophical essay rather than a list of the greatest essays of 2024.\\n\\nIf you would like, I can try to provide a different response or explore other options to answer your question. Please let me know how I can assist you further.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_exectuor.invoke({'input':'Give me 10 greatest essays of 2024 ??'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.ddg_search import DuckDuckGoSearchRun\n",
    "ddg_search = DuckDuckGoSearchRun()\n",
    "tools = [wiki, arxiv, retriever_tool, ddg_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m/tool-use>{\"tool_calls\": [{\"id\": \"pending\", \"type\": \"function\", \"function\": {\"name\": \"wikipedia\"}, \"parameters\": {\"query\": \"memory\"}}]}</tool-use>\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Do you have memory of our past conversations ??',\n",
       " 'output': '/tool-use>{\"tool_calls\": [{\"id\": \"pending\", \"type\": \"function\", \"function\": {\"name\": \"wikipedia\"}, \"parameters\": {\"query\": \"memory\"}}]}</tool-use>'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_exectuor.invoke({'input':'Do you have memory of our past conversations ??'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [ddg_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DuckDuckGoSearchRun(api_wrapper=DuckDuckGoSearchAPIWrapper(region='wt-wt', safesearch='moderate', time='y', max_results=5, backend='auto', source='text'))]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x73ccc4568c20>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x73ccc4568c20>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x73cc6b09a5d0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x73cc6b062900>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'Essay Search', 'description': 'Ask me about this essay...', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[DuckDuckGoSearchRun(api_wrapper=DuckDuckGoSearchAPIWrapper(region='wt-wt', safesearch='moderate', time='y', max_results=5, backend='auto', source='text'))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_exectuor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_exectuor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Essay Search` with `{'query': 'greatest essays 2024'}`\n",
      "\n",
      "\n",
      "\u001b[0mEssay Search is not a valid tool, try one of [duckduckgo_search]."
     ]
    },
    {
     "ename": "APIError",
     "evalue": "Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# agent_exectuor.invoke({'input':'Do you like apples and oranges??'})\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43magent_exectuor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGive me 10 greatest essays of 2024 ??\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/agent-env/lib/python3.12/site-packages/langchain/chains/base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m/opt/conda/envs/agent-env/lib/python3.12/site-packages/langchain/chains/base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/envs/agent-env/lib/python3.12/site-packages/langchain/agents/agent.py:1624\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1622\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1624\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1633\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1634\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/envs/agent-env/lib/python3.12/site-packages/langchain/agents/agent.py:1332\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1323\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1328\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m   1330\u001b[0m         [\n\u001b[1;32m   1331\u001b[0m             a\n\u001b[0;32m-> 1332\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[1;32m   1333\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1334\u001b[0m                 color_mapping,\n\u001b[1;32m   1335\u001b[0m                 inputs,\n\u001b[1;32m   1336\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1337\u001b[0m                 run_manager,\n\u001b[1;32m   1338\u001b[0m             )\n\u001b[1;32m   1339\u001b[0m         ]\n\u001b[1;32m   1340\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/agent-env/lib/python3.12/site-packages/langchain/agents/agent.py:1358\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m   1357\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1358\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_action_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1364\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/envs/agent-env/lib/python3.12/site-packages/langchain/agents/agent.py:581\u001b[0m, in \u001b[0;36mRunnableMultiActionAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m final_output: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_runnable:\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[0;32m--> 581\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunnable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/agent-env/lib/python3.12/site-packages/langchain_core/runnables/base.py:3409\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3403\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[1;32m   3404\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3405\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   3406\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3407\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   3408\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 3409\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/envs/agent-env/lib/python3.12/site-packages/langchain_core/runnables/base.py:3396\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   3391\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3392\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   3393\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3394\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   3395\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 3396\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[1;32m   3397\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   3398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[1;32m   3399\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m   3400\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3401\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/agent-env/lib/python3.12/site-packages/langchain_core/runnables/base.py:2196\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   2194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2195\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 2196\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   2197\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   2198\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m/opt/conda/envs/agent-env/lib/python3.12/site-packages/langchain_core/runnables/base.py:3359\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3357\u001b[0m         final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(final_pipeline, config)\n\u001b[0;32m-> 3359\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m final_pipeline\n",
      "File \u001b[0;32m/opt/conda/envs/agent-env/lib/python3.12/site-packages/langchain_core/runnables/base.py:1414\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1411\u001b[0m final: Input\n\u001b[1;32m   1412\u001b[0m got_first_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1414\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1415\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The default implementation of transform is to buffer input and\u001b[39;49;00m\n\u001b[1;32m   1416\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# then call stream.\u001b[39;49;00m\n\u001b[1;32m   1417\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# It'll attempt to gather all input into a single chunk using\u001b[39;49;00m\n\u001b[1;32m   1418\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# the `+` operator.\u001b[39;49;00m\n\u001b[1;32m   1419\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If the input is not addable, then we'll assume that we can\u001b[39;49;00m\n\u001b[1;32m   1420\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# only operate on the last chunk,\u001b[39;49;00m\n\u001b[1;32m   1421\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# and we'll iterate until we get to the last chunk.\u001b[39;49;00m\n\u001b[1;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgot_first_val\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/agent-env/lib/python3.12/site-packages/langchain_core/runnables/base.py:5567\u001b[0m, in \u001b[0;36mRunnableBindingBase.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5561\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   5562\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5563\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   5564\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5565\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   5566\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 5567\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   5568\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   5569\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   5570\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[1;32m   5571\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/agent-env/lib/python3.12/site-packages/langchain_core/runnables/base.py:1432\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1429\u001b[0m             final \u001b[38;5;241m=\u001b[39m ichunk\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/envs/agent-env/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:415\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrate_limiter\u001b[38;5;241m.\u001b[39macquire(blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n",
      "File \u001b[0;32m/opt/conda/envs/agent-env/lib/python3.12/site-packages/langchain_groq/chat_models.py:516\u001b[0m, in \u001b[0;36mChatGroq._stream\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[1;32m    515\u001b[0m default_chunk_class: Type[BaseMessageChunk] \u001b[38;5;241m=\u001b[39m AIMessageChunk\n\u001b[0;32m--> 516\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/agent-env/lib/python3.12/site-packages/groq/_streaming.py:46\u001b[0m, in \u001b[0;36mStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[_T]:\n\u001b[0;32m---> 46\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/agent-env/lib/python3.12/site-packages/groq/_streaming.py:91\u001b[0m, in \u001b[0;36mStream.__stream__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m message \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     89\u001b[0m                 message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred during streaming\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 91\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m APIError(\n\u001b[1;32m     92\u001b[0m                 message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m     93\u001b[0m                 request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mrequest,\n\u001b[1;32m     94\u001b[0m                 body\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     95\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m process_data(data\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m\"\u001b[39m: sse\u001b[38;5;241m.\u001b[39mevent}, cast_to\u001b[38;5;241m=\u001b[39mcast_to, response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Ensure the entire stream is consumed\u001b[39;00m\n",
      "\u001b[0;31mAPIError\u001b[0m: Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details."
     ]
    }
   ],
   "source": [
    "# agent_exectuor.invoke({'input':'Do you like apples and oranges??'})\n",
    "\n",
    "agent_exectuor.invoke({'input':'Give me 10 greatest essays of 2024 ??'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
